{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092f6dd3-620d-477e-a539-c904fff0eeaa",
   "metadata": {},
   "source": [
    "# A Simple RNN from Scratch\n",
    "---\n",
    "\n",
    "*COSCI 223 - Machine Learning 3*\n",
    "\n",
    "*Prepared by Sebastian C. Iba√±ez*\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/aim-msds/msds2023-ml3/blob/main/notebooks/rnn/01-simple-rnn.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"float: left;\"></a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2824f-09c4-4266-90c9-aa122cdd4ee1",
   "metadata": {},
   "source": [
    "## Building A Simple RNN from Sractch with PyTorch\n",
    "---\n",
    "\n",
    "In this section, we'll use PyTorch's primitive operations to set-up a sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4b8c9c-e333-49c8-bcc2-a61a94ed39e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T03:14:00.716480Z",
     "iopub.status.busy": "2023-04-22T03:14:00.716480Z",
     "iopub.status.idle": "2023-04-22T03:14:02.152650Z",
     "shell.execute_reply": "2023-04-22T03:14:02.152650Z",
     "shell.execute_reply.started": "2023-04-22T03:14:00.716480Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee0fbc3-f906-4a41-86b9-064cf1ae74a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T03:14:02.154652Z",
     "iopub.status.busy": "2023-04-22T03:14:02.153651Z",
     "iopub.status.idle": "2023-04-22T03:14:02.168665Z",
     "shell.execute_reply": "2023-04-22T03:14:02.168665Z",
     "shell.execute_reply.started": "2023-04-22T03:14:02.154652Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "tensor([1., 2., 3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "# Create raw data\n",
    "seq_len = 5 # sequence length\n",
    "\n",
    "data = torch.arange(seq_len).float() + 1.\n",
    "\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be132594-8cef-4682-9d87-efa9f8a60a5c",
   "metadata": {},
   "source": [
    "Let's reshape the data into a more general form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee05692b-55e2-4a7f-9c76-277abfccbbe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T03:14:02.169667Z",
     "iopub.status.busy": "2023-04-22T03:14:02.169667Z",
     "iopub.status.idle": "2023-04-22T03:14:02.200693Z",
     "shell.execute_reply": "2023-04-22T03:14:02.200693Z",
     "shell.execute_reply.started": "2023-04-22T03:14:02.169667Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 1])\n",
      "tensor([[[1.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [5.]]])\n"
     ]
    }
   ],
   "source": [
    "# Reshape\n",
    "batch_size = 1\n",
    "input_size = 1 # number of features\n",
    "\n",
    "x = data.view(batch_size, seq_len, input_size) # shape=(batch, timesteps, feature)\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7c4de7-8eb3-4956-9d29-36b637824037",
   "metadata": {},
   "source": [
    "Next, let's initialize the hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a7ea29e-b48c-41b8-9548-0f441cbdfc01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T03:14:02.201694Z",
     "iopub.status.busy": "2023-04-22T03:14:02.201694Z",
     "iopub.status.idle": "2023-04-22T03:14:02.216709Z",
     "shell.execute_reply": "2023-04-22T03:14:02.216709Z",
     "shell.execute_reply.started": "2023-04-22T03:14:02.201694Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n",
      "tensor([[0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize hidden state\n",
    "hidden_size = 4\n",
    "h0 = torch.zeros((input_size, hidden_size)) # shape=(input_size, hidden size)\n",
    "\n",
    "print(h0.shape)\n",
    "print(h0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b71ae6c-2934-4ece-8d03-36afc6fa2a60",
   "metadata": {},
   "source": [
    "Now let's initialize the weights of the RNN,\n",
    "\n",
    "$$h_t = \\tanh(W_{xh}x_t + W_{hh}h_{t-1} + b_h)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19f31d6f-9a73-4bd3-bcd1-a2aece34c2f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T03:14:02.218710Z",
     "iopub.status.busy": "2023-04-22T03:14:02.217710Z",
     "iopub.status.idle": "2023-04-22T03:14:02.232723Z",
     "shell.execute_reply": "2023-04-22T03:14:02.232723Z",
     "shell.execute_reply.started": "2023-04-22T03:14:02.218710Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n",
      "tensor([[ 1.5410, -0.2934, -2.1788,  0.5684]])\n",
      "torch.Size([4, 4])\n",
      "tensor([[-0.3561,  0.4372,  0.4913, -0.2041],\n",
      "        [-0.0885,  0.5239, -0.6659,  0.8504],\n",
      "        [-1.0438, -1.3453,  0.7854,  0.9928],\n",
      "        [-0.1932, -0.3090,  0.5026, -0.8594]])\n",
      "torch.Size([4])\n",
      "tensor([0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Initialize random weights\n",
    "torch.manual_seed(0)\n",
    "W_xh = torch.randn((input_size, hidden_size))  # shape=(input_size, hidden size)\n",
    "W_hh = torch.randn((hidden_size, hidden_size)) # shape=(hidden size,  hidden size)\n",
    "b_h  = torch.zeros((hidden_size))              # shape=(hidden size)\n",
    "\n",
    "print(W_xh.shape)\n",
    "print(W_xh)\n",
    "print(W_hh.shape)\n",
    "print(W_hh)\n",
    "print(b_h.shape)\n",
    "print(b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c2d16-d492-482c-b9e7-2a7ee72b4389",
   "metadata": {},
   "source": [
    "Now for the forward pass!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64b7f52-d13d-4eb9-8649-221fb44162c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T03:14:02.234040Z",
     "iopub.status.busy": "2023-04-22T03:14:02.234040Z",
     "iopub.status.idle": "2023-04-22T03:14:02.247956Z",
     "shell.execute_reply": "2023-04-22T03:14:02.247956Z",
     "shell.execute_reply.started": "2023-04-22T03:14:02.234040Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0 = tensor([[0., 0., 0., 0.]])\n",
      "h1 = tensor([[ 0.9123, -0.2853, -0.9747,  0.5142]])\n",
      "h2 = tensor([[ 0.9988,  0.6723, -0.9996, -0.6054]])\n",
      "h3 = tensor([[ 1.0000,  0.8938, -1.0000,  0.9218]])\n",
      "h4 = tensor([[ 1.0000,  0.6597, -1.0000,  0.7797]])\n",
      "h5 = tensor([[ 1.0000,  0.3970, -1.0000,  0.9115]])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass (w/ tanh activation)\n",
    "h = h0\n",
    "print(f'h0 = {h}')\n",
    "for t in range(seq_len):\n",
    "    h = torch.tanh(x[:, t, :]@W_xh + h@W_hh + b_h)\n",
    "    print(f'h{t+1} = {h}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a70c41-a47b-4b82-b03f-6a608b01da12",
   "metadata": {},
   "source": [
    "Here's a more efficient implementation of the forward pass using only 1 matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1716c90f-3dd8-4604-9748-a7bd762691cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T03:14:02.249958Z",
     "iopub.status.busy": "2023-04-22T03:14:02.249958Z",
     "iopub.status.idle": "2023-04-22T03:14:02.264488Z",
     "shell.execute_reply": "2023-04-22T03:14:02.263970Z",
     "shell.execute_reply.started": "2023-04-22T03:14:02.249958Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0 = tensor([[0., 0., 0., 0.]])\n",
      "h1 = tensor([[ 0.9123, -0.2853, -0.9747,  0.5142]])\n",
      "h2 = tensor([[ 0.9988,  0.6723, -0.9996, -0.6054]])\n",
      "h3 = tensor([[ 1.0000,  0.8938, -1.0000,  0.9218]])\n",
      "h4 = tensor([[ 1.0000,  0.6597, -1.0000,  0.7797]])\n",
      "h5 = tensor([[ 1.0000,  0.3970, -1.0000,  0.9115]])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass (more efficient)\n",
    "h = h0\n",
    "print(f'h0 = {h}')\n",
    "for t in range(seq_len):\n",
    "    h = torch.tanh(torch.cat((x[:, t, :], h), axis=1)@torch.cat((W_xh, W_hh), axis=0) + b_h) # more efficient\n",
    "    print(f'h{t+1} = {h}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b935d7c-b596-4518-9987-c78efc80e76b",
   "metadata": {},
   "source": [
    "Finally, we can verify that our model specification is correct using PyTorch's built-in [RNN class](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html).\n",
    "\n",
    "Note that PyTorch uses a slightly different notation for their RNN equation:\n",
    "\n",
    "$$h_t = \\tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5905f26d-cc4f-49ed-a208-8f1c7efc1deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T03:14:02.264971Z",
     "iopub.status.busy": "2023-04-22T03:14:02.264971Z",
     "iopub.status.idle": "2023-04-22T03:14:02.279898Z",
     "shell.execute_reply": "2023-04-22T03:14:02.279898Z",
     "shell.execute_reply.started": "2023-04-22T03:14:02.264971Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight_ih_l0', Parameter containing:\n",
      "tensor([[-0.0037],\n",
      "        [ 0.2682],\n",
      "        [-0.4115],\n",
      "        [-0.3680]], requires_grad=True))\n",
      "('weight_hh_l0', Parameter containing:\n",
      "tensor([[-0.1926,  0.1341, -0.0099,  0.3964],\n",
      "        [-0.0444,  0.1323, -0.1511, -0.0983],\n",
      "        [-0.4777, -0.3311, -0.2061,  0.0185],\n",
      "        [ 0.1977,  0.3000, -0.3390, -0.2177]], requires_grad=True))\n",
      "('bias_ih_l0', Parameter containing:\n",
      "tensor([ 0.1816,  0.4152, -0.1029,  0.3742], requires_grad=True))\n",
      "('bias_hh_l0', Parameter containing:\n",
      "tensor([-0.0806,  0.0529,  0.4527, -0.4638], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Create RNN\n",
    "rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True) # by default, the expected shape is (timestep, batch, feature)\n",
    "\n",
    "# Check parameters\n",
    "for p in rnn.named_parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd110194-a84b-4d33-8fc5-3ea17c013b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T03:14:02.280898Z",
     "iopub.status.busy": "2023-04-22T03:14:02.280898Z",
     "iopub.status.idle": "2023-04-22T03:14:02.295912Z",
     "shell.execute_reply": "2023-04-22T03:14:02.295912Z",
     "shell.execute_reply.started": "2023-04-22T03:14:02.280898Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Overwrite parameters to our random init\n",
    "rnn.weight_ih_l0 = nn.Parameter(W_xh.T)\n",
    "rnn.weight_hh_l0 = nn.Parameter(W_hh.T)\n",
    "rnn.bias_hh_l0   = nn.Parameter(torch.zeros(rnn.bias_hh_l0.shape))\n",
    "rnn.bias_ih_l0   = nn.Parameter(torch.zeros(rnn.bias_ih_l0.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2723f8e6-8936-4625-adc5-29b633cca826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T03:14:02.296913Z",
     "iopub.status.busy": "2023-04-22T03:14:02.296913Z",
     "iopub.status.idle": "2023-04-22T03:14:02.311617Z",
     "shell.execute_reply": "2023-04-22T03:14:02.311617Z",
     "shell.execute_reply.started": "2023-04-22T03:14:02.296913Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9123, -0.2853, -0.9747,  0.5142],\n",
       "         [ 0.9988,  0.6723, -0.9996, -0.6054],\n",
       "         [ 1.0000,  0.8938, -1.0000,  0.9218],\n",
       "         [ 1.0000,  0.6597, -1.0000,  0.7797],\n",
       "         [ 1.0000,  0.3970, -1.0000,  0.9115]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass\n",
    "output, h_n = rnn(x) # RNN returns a tuple of (all hidden states, last hidden state)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6135f0c-c0a8-446f-89b7-30824915fbe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T03:14:02.312618Z",
     "iopub.status.busy": "2023-04-22T03:14:02.312618Z",
     "iopub.status.idle": "2023-04-22T03:14:02.327056Z",
     "shell.execute_reply": "2023-04-22T03:14:02.327056Z",
     "shell.execute_reply.started": "2023-04-22T03:14:02.312618Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  0.3970, -1.0000,  0.9115]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:master-env-v1]",
   "language": "python",
   "name": "conda-env-master-env-v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
