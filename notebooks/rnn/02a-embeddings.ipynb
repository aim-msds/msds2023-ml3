{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092f6dd3-620d-477e-a539-c904fff0eeaa",
   "metadata": {},
   "source": [
    "# Embedding Layers\n",
    "---\n",
    "\n",
    "*COSCI 223 - Machine Learning 3*\n",
    "\n",
    "*Prepared by Sebastian C. Iba√±ez*\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/aim-msds/msds2023-ml3/blob/main/notebooks/rnn/01-simple-rnn.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"float: left;\"></a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4b8c9c-e333-49c8-bcc2-a61a94ed39e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T11:03:45.296399Z",
     "iopub.status.busy": "2023-05-01T11:03:45.295398Z",
     "iopub.status.idle": "2023-05-01T11:03:46.614154Z",
     "shell.execute_reply": "2023-05-01T11:03:46.614154Z",
     "shell.execute_reply.started": "2023-05-01T11:03:45.296399Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d94199-ce3e-4ce4-b4a8-cbf575315820",
   "metadata": {},
   "source": [
    "## What does an embedding layer do?\n",
    "\n",
    "---\n",
    "\n",
    "An **embedding layer** is a type of hidden layer in a neural network that transforms high-dimensional categorical input data (such as words) into low-dimensional vectors that capture some of the meaning or structure of the input. \n",
    "\n",
    "For example, if we have a vocabulary of 2000 words, each word can be represented by a one-hot vector of length 2000, where only one element is 1 and the rest are 0. This is very inefficient and sparse. \n",
    "\n",
    "An embedding layer can map each word to a vector of length 50 (or any other number) that contains some numerical values. \n",
    "\n",
    "These values are <u>learned</u> during the training process and can reflect how similar or different words are in terms of semantics or syntax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74cd73f0-f778-471e-8678-3c83147be120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T11:03:46.616157Z",
     "iopub.status.busy": "2023-05-01T11:03:46.616157Z",
     "iopub.status.idle": "2023-05-01T11:03:46.630169Z",
     "shell.execute_reply": "2023-05-01T11:03:46.630169Z",
     "shell.execute_reply.started": "2023-05-01T11:03:46.616157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e', 'f']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989e15c7-7b5f-4dca-803c-d0291b2bc6fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T11:03:46.631170Z",
     "iopub.status.busy": "2023-05-01T11:03:46.631170Z",
     "iopub.status.idle": "2023-05-01T11:03:46.662189Z",
     "shell.execute_reply": "2023-05-01T11:03:46.662189Z",
     "shell.execute_reply.started": "2023-05-01T11:03:46.631170Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens must be converted into integers\n",
    "vocab.index('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b331cdee-c39b-4f57-8f4e-533d8fba1dd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T11:03:46.663189Z",
     "iopub.status.busy": "2023-05-01T11:03:46.663189Z",
     "iopub.status.idle": "2023-05-01T11:03:46.678018Z",
     "shell.execute_reply": "2023-05-01T11:03:46.678018Z",
     "shell.execute_reply.started": "2023-05-01T11:03:46.663189Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We place it in a torch tensor\n",
    "torch.tensor([vocab.index('c')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e332330-f61b-4f95-8af1-cd3f264dd6dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T11:03:46.679018Z",
     "iopub.status.busy": "2023-05-01T11:03:46.679018Z",
     "iopub.status.idle": "2023-05-01T11:03:46.694032Z",
     "shell.execute_reply": "2023-05-01T11:03:46.694032Z",
     "shell.execute_reply.started": "2023-05-01T11:03:46.679018Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934]])\n",
      "tensor([[-2.1788,  0.5684]])\n",
      "tensor([[-1.0845, -1.3986]])\n",
      "tensor([[0.4033, 0.8380]])\n",
      "tensor([[-0.7193, -0.4033]])\n",
      "tensor([[-0.5966,  0.1820]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Create an embedding layer\n",
    "embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=2)\n",
    "\n",
    "for c in vocab:\n",
    "    token = torch.tensor([vocab.index(c)])\n",
    "    print(embedding_layer(token).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23432d64-17eb-4808-905b-46d0537becc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T11:03:46.696034Z",
     "iopub.status.busy": "2023-05-01T11:03:46.695033Z",
     "iopub.status.idle": "2023-05-01T11:03:46.709802Z",
     "shell.execute_reply": "2023-05-01T11:03:46.709802Z",
     "shell.execute_reply.started": "2023-05-01T11:03:46.696034Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.5410, -0.2934],\n",
      "        [-2.1788,  0.5684],\n",
      "        [-1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380],\n",
      "        [-0.7193, -0.4033],\n",
      "        [-0.5966,  0.1820]], requires_grad=True)\n",
      "torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "# Embedding layers are implemented as learnable lookup tables\n",
    "for p in embedding_layer.parameters():\n",
    "    print(p)\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c791484-ceea-4d37-b18e-7f8b68566ad9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T11:03:46.711804Z",
     "iopub.status.busy": "2023-05-01T11:03:46.711804Z",
     "iopub.status.idle": "2023-05-01T11:03:46.725044Z",
     "shell.execute_reply": "2023-05-01T11:03:46.725044Z",
     "shell.execute_reply.started": "2023-05-01T11:03:46.711804Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5410, -0.2934]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2x6 weight matrix times 6x1 OHE -> transpose\n",
    "(embedding_layer.weight.T @ torch.tensor([[1., 0., 0., 0., 0., 0.]]).T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9655a9d-4aba-4024-a306-a9a0cf02a068",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "---\n",
    "\n",
    "1. https://discuss.pytorch.org/t/what-is-nn-embedding-exactly-doing/12521\n",
    "\n",
    "2. https://discuss.pytorch.org/t/how-does-nn-embedding-work/88518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec8ca6-5b5f-4092-87bf-edceeb5ef9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:master-env-v1]",
   "language": "python",
   "name": "conda-env-master-env-v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
