{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092f6dd3-620d-477e-a539-c904fff0eeaa",
   "metadata": {},
   "source": [
    "# Character-Level Language Models with RNNs\n",
    "---\n",
    "\n",
    "*COSCI 223 - Machine Learning 3*\n",
    "\n",
    "*Prepared by Sebastian C. Ibañez*\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/aim-msds/msds2023-ml3/blob/main/notebooks/rnn/01-simple-rnn.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"float: left;\"></a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4b8c9c-e333-49c8-bcc2-a61a94ed39e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:20.436443Z",
     "iopub.status.busy": "2023-05-01T07:56:20.436443Z",
     "iopub.status.idle": "2023-05-01T07:56:21.755192Z",
     "shell.execute_reply": "2023-05-01T07:56:21.755192Z",
     "shell.execute_reply.started": "2023-05-01T07:56:20.436443Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0beaef-8c51-4bd1-9a82-009b2ccc0d23",
   "metadata": {},
   "source": [
    "## PyTorch Implementation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, our goal is to create a character-level language model using a simple RNN that is trained to generate names. The data is from [ssa.gov](https://www.ssa.gov/oact/babynames/https://www.ssa.gov/oact/babynames/) and includes a list of baby names.\n",
    "\n",
    "*Check out this Very Cool™ blog post by Andrej Karpathy from 2015: [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edc9e67-665f-4e3b-9ffe-8092bd87356c",
   "metadata": {},
   "source": [
    "Let's look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a91925e-5f49-4c7a-9322-89d3fa45ad6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:21.757196Z",
     "iopub.status.busy": "2023-05-01T07:56:21.756195Z",
     "iopub.status.idle": "2023-05-01T07:56:21.770207Z",
     "shell.execute_reply": "2023-05-01T07:56:21.770207Z",
     "shell.execute_reply.started": "2023-05-01T07:56:21.757196Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "with open('data/names.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    names = text.splitlines()\n",
    "\n",
    "print(names[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b259dea-7f3f-43f2-8925-d0c136e4d696",
   "metadata": {},
   "source": [
    "Next, let's create a vocabulary to store all the unique tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74cd73f0-f778-471e-8678-3c83147be120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:21.771209Z",
     "iopub.status.busy": "2023-05-01T07:56:21.771209Z",
     "iopub.status.idle": "2023-05-01T07:56:21.786222Z",
     "shell.execute_reply": "2023-05-01T07:56:21.786222Z",
     "shell.execute_reply.started": "2023-05-01T07:56:21.771209Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 26\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# Create raw vocabulary\n",
    "raw_vocab = sorted(list(set(text)))[1:] # drop first token which is \\n\n",
    "vocab_size = len(raw_vocab)\n",
    "\n",
    "print(f'Number of unique tokens: {vocab_size}')\n",
    "print(raw_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f584c3ec-20f8-4416-8d2b-fc599c368c83",
   "metadata": {},
   "source": [
    "Before we proceed, we're going to append special start and end tokens to every name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337da7ba-ac63-42b3-9e96-d88fa6dd7e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:21.787224Z",
     "iopub.status.busy": "2023-05-01T07:56:21.787224Z",
     "iopub.status.idle": "2023-05-01T07:56:21.802208Z",
     "shell.execute_reply": "2023-05-01T07:56:21.802208Z",
     "shell.execute_reply.started": "2023-05-01T07:56:21.787224Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>emma<e>', '<s>olivia<e>', '<s>ava<e>', '<s>isabella<e>', '<s>sophia<e>']\n"
     ]
    }
   ],
   "source": [
    "names = [f'<s>{n}<e>' for n in names]\n",
    "print(names[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8065f26-e233-4d77-82aa-4872d5b08dfd",
   "metadata": {},
   "source": [
    "PyTorch has some useful utilities for easy processing of text data via `torchtext.vocab`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19736af1-28dc-4e88-b2ef-cfcce508ca33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:21.803209Z",
     "iopub.status.busy": "2023-05-01T07:56:21.803209Z",
     "iopub.status.idle": "2023-05-01T07:56:21.818222Z",
     "shell.execute_reply": "2023-05-01T07:56:21.818222Z",
     "shell.execute_reply.started": "2023-05-01T07:56:21.803209Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71627e6-4281-40f6-8ffd-467aa0d8bcb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:21.819223Z",
     "iopub.status.busy": "2023-05-01T07:56:21.819223Z",
     "iopub.status.idle": "2023-05-01T07:56:21.978368Z",
     "shell.execute_reply": "2023-05-01T07:56:21.978368Z",
     "shell.execute_reply.started": "2023-05-01T07:56:21.819223Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 28\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# Create torchtext vocab\n",
    "vocab = build_vocab_from_iterator(raw_vocab, specials=['<s>', '<e>'])\n",
    "\n",
    "print(f'Vocabulary Size: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e847c3c-30fb-4c7d-94f5-ce691014d71f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:21.980370Z",
     "iopub.status.busy": "2023-05-01T07:56:21.980370Z",
     "iopub.status.idle": "2023-05-01T07:56:21.993650Z",
     "shell.execute_reply": "2023-05-01T07:56:21.993650Z",
     "shell.execute_reply.started": "2023-05-01T07:56:21.980370Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>emma<e>']\n",
      "tensor([ 0,  6, 14, 14,  2,  1])\n"
     ]
    }
   ],
   "source": [
    "# Convert name to a tensor of integers\n",
    "def name_to_tensor(name):\n",
    "    vocab_input = [name[:3]] + list(name[3:-3]) + [name[-3:]]\n",
    "    return torch.tensor(vocab(vocab_input), dtype=torch.long)\n",
    "\n",
    "print([names[0]])\n",
    "print(name_to_tensor(names[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8104c-bf6c-44a5-8caf-d5c575ee118f",
   "metadata": {},
   "source": [
    "In order to interpret our predictions at inference time, we can use the `vocab.lookup_tokens` function to convert an index (i.e., the integer encoding) back into an actual token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaee3e7d-a0d4-458b-be9e-f72b86a1d7c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:21.994651Z",
     "iopub.status.busy": "2023-05-01T07:56:21.994651Z",
     "iopub.status.idle": "2023-05-01T07:56:22.009664Z",
     "shell.execute_reply": "2023-05-01T07:56:22.009664Z",
     "shell.execute_reply.started": "2023-05-01T07:56:21.994651Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 16, 13, 10, 23, 10,  2,  1])\n",
      "['<s>olivia<e>']\n"
     ]
    }
   ],
   "source": [
    "# Reverse lookup\n",
    "def tensor_to_name(input_tensor):\n",
    "    return ''.join(vocab.lookup_tokens(input_tensor.tolist()))\n",
    "\n",
    "input_tensor = name_to_tensor(names[1])\n",
    "print(input_tensor)\n",
    "print([tensor_to_name(input_tensor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bda774-bb8e-439e-be8c-ae653aafd7ea",
   "metadata": {},
   "source": [
    "Now, let's prepare our dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb67b97-3544-4695-b686-9bbba070bca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:22.010665Z",
     "iopub.status.busy": "2023-05-01T07:56:22.010665Z",
     "iopub.status.idle": "2023-05-01T07:56:22.025432Z",
     "shell.execute_reply": "2023-05-01T07:56:22.025432Z",
     "shell.execute_reply.started": "2023-05-01T07:56:22.010665Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, names):\n",
    "        self.names = names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return name_to_tensor(self.names[idx])\n",
    "    \n",
    "names_ds = NamesDataset(names) \n",
    "names_dl = DataLoader(names_ds, batch_size=1, shuffle=True) # Will not work with batch_size > 1 because you can't stack observations of different lengths!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bff7db5-4d7e-4e0b-a0bc-281716ce7ce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:22.026435Z",
     "iopub.status.busy": "2023-05-01T07:56:22.026435Z",
     "iopub.status.idle": "2023-05-01T07:56:22.041447Z",
     "shell.execute_reply": "2023-05-01T07:56:22.041447Z",
     "shell.execute_reply.started": "2023-05-01T07:56:22.026435Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 15,  2,  2, 14,  2]) -> <s>naama\n",
      "tensor([15,  2,  2, 14,  2,  1]) -> naama<e>\n"
     ]
    }
   ],
   "source": [
    "# Split name into input, output pairs\n",
    "for name in names_dl:\n",
    "    x = name[0, :-1]\n",
    "    y = name[0, 1:]\n",
    "    print(f'{x} -> {tensor_to_name(x)}')\n",
    "    print(f'{y} -> {tensor_to_name(y)}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bcedc1e-ad79-4704-a822-0d2d653d28f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:22.042448Z",
     "iopub.status.busy": "2023-05-01T07:56:22.042448Z",
     "iopub.status.idle": "2023-05-01T07:56:22.088921Z",
     "shell.execute_reply": "2023-05-01T07:56:22.088921Z",
     "shell.execute_reply.started": "2023-05-01T07:56:22.042448Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#dev = torch.device('cpu')\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d29f420-5336-4f1f-ad6d-3590f17fbea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:22.089922Z",
     "iopub.status.busy": "2023-05-01T07:56:22.089922Z",
     "iopub.status.idle": "2023-05-01T07:56:22.104935Z",
     "shell.execute_reply": "2023-05-01T07:56:22.104935Z",
     "shell.execute_reply.started": "2023-05-01T07:56:22.089922Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CharacterLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(CharacterLM, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, batch_first=True) # Make sure to set batch_first=True!\n",
    "        self.output_layer = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embed = self.embedding_layer(x)\n",
    "        rnn_output, hn = self.rnn(x_embed)\n",
    "        logits = self.output_layer(rnn_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "511967fe-7e73-4730-9c39-13b018b10eba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T07:56:22.105936Z",
     "iopub.status.busy": "2023-05-01T07:56:22.105936Z",
     "iopub.status.idle": "2023-05-01T08:06:44.848301Z",
     "shell.execute_reply": "2023-05-01T08:06:44.848301Z",
     "shell.execute_reply.started": "2023-05-01T07:56:22.105936Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5529f6b204234523ab0c05c99732b426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc53d25255d42e197b2618858d3aa8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss = 2.2845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d837d645aca42f2b1eb4ff19dabbe49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss = 2.2613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c8d8b935f0414eabb91cd390c97b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss = 2.2501\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba085c1c5ba84871a23e3bb76e7e964c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss = 2.2454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02b0050927b4c149ebc66594ff41066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss = 2.2400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d431e07beea04a70aa75ae9969850252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss = 2.2393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b177655d16041c9b59236637de6e456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss = 2.2357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8d01b02fa34ad3861469edf2a375d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss = 2.2374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbc97f3b2254bb18130ece764ad06ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss = 2.2364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbcf46187034e9993c4bafb5efd6291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss = 2.2304\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# Hyperparams\n",
    "epochs = 10\n",
    "vocab_size = len(vocab)\n",
    "embedding_size = 8\n",
    "hidden_size = 16\n",
    "lr = 0.001\n",
    "\n",
    "# Create model\n",
    "model = CharacterLM(vocab_size, embedding_size, hidden_size)\n",
    "model.to(dev)\n",
    "\n",
    "# Loss, optimizer\n",
    "loss_fn = F.cross_entropy\n",
    "opt = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for e in trange(epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    for name in tqdm(names_dl):\n",
    "        # Split, move to device, add batch dimension\n",
    "        xb = name[0, :-1].to(dev).unsqueeze(0)\n",
    "        yb = name[0, 1:].to(dev).unsqueeze(0)\n",
    "        \n",
    "        # Forward\n",
    "        yb_hat = model(xb)\n",
    "\n",
    "        # Loss\n",
    "        loss = loss_fn(yb_hat.view(-1, vocab_size), yb.view(-1)) # Reshape outputs, cross entropy loss has no notion of \"timesteps\" so we collapse the timestep dim with the batch dim\n",
    "\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        metrics = {'train_loss': 0}\n",
    "        for name in names_dl:\n",
    "            xb = name[0, :-1].to(dev).unsqueeze(0)\n",
    "            yb = name[0, 1:].to(dev).unsqueeze(0)\n",
    "            yb_hat = model(xb)\n",
    "            metrics['train_loss'] += loss_fn(yb_hat.view(-1, vocab_size), yb.view(-1)).item()\n",
    "    \n",
    "    # Metrics\n",
    "    train_loss = metrics['train_loss']/len(names_ds)\n",
    "    print(f'Epoch {e+1}: train_loss = {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31185762-c94c-4a60-889f-ed119bc7d6c4",
   "metadata": {},
   "source": [
    "Before we start sampling, let's briefly describe a common parameter used to control the \"confidence\" of our logits called **temperature**.\n",
    "\n",
    "*Note: The temperature parameter controls the distribution's [entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)), which is a measure of uncertainty.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9bad76a-6634-452a-9508-11513cd386ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T08:06:44.850302Z",
     "iopub.status.busy": "2023-05-01T08:06:44.849301Z",
     "iopub.status.idle": "2023-05-01T08:06:44.864316Z",
     "shell.execute_reply": "2023-05-01T08:06:44.864316Z",
     "shell.execute_reply.started": "2023-05-01T08:06:44.850302Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  logits   = tensor([ 0.8033,  0.1748,  0.0890, -0.6137,  0.0462])\n",
      "temp 0.3   = [0.76651555 0.0943533  0.07087104 0.00681102 0.06144912]\n",
      "temp 0.5   = [0.5546469  0.15781862 0.13291845 0.03260102 0.12201507]\n",
      "temp 1.0   = [0.36570734 0.19507629 0.17902678 0.08866271 0.17152685]\n",
      "temp 3.0   = [0.25002265 0.20276965 0.19704895 0.15590084 0.19425796]\n",
      "temp 100.0 = [0.20140965 0.20014787 0.19997612 0.19857581 0.19989054]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3)\n",
    "logits = torch.randn(size=(5,))\n",
    "\n",
    "print(f'  logits   = {logits}')\n",
    "print(f'temp 0.3   = {F.softmax(logits/0.3, dim=0).numpy()}')\n",
    "print(f'temp 0.5   = {F.softmax(logits/0.5, dim=0).numpy()}')\n",
    "print(f'temp 1.0   = {F.softmax(logits/1.0, dim=0).numpy()}')\n",
    "print(f'temp 3.0   = {F.softmax(logits/3.0, dim=0).numpy()}')\n",
    "print(f'temp 100.0 = {F.softmax(logits/100.0, dim=0).numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ef5853-e7da-4af6-bc6c-34577b11ca55",
   "metadata": {},
   "source": [
    "Notice what happens to the probabilities as we divide our logits by the temperature parameter. \n",
    "\n",
    "Lowering the temperature below 1.0 increases the \"confidence\" or \"certainty\" of the distribution, while increasing it does the opposite. \n",
    "\n",
    "This will allow us to control how \"wild\" the generated text is when we sample it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "427427a5-8251-48ea-b6bf-dbb0c19b3f06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T08:07:40.298899Z",
     "iopub.status.busy": "2023-05-01T08:07:40.298899Z",
     "iopub.status.idle": "2023-05-01T08:07:40.348945Z",
     "shell.execute_reply": "2023-05-01T08:07:40.348945Z",
     "shell.execute_reply.started": "2023-05-01T08:07:40.298899Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#torch.save(model, 'torch_checkpoints/name-generator-rnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d7f6e55-7135-4b00-9791-12c98a7ce996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T08:08:56.310915Z",
     "iopub.status.busy": "2023-05-01T08:08:56.310915Z",
     "iopub.status.idle": "2023-05-01T08:08:56.354956Z",
     "shell.execute_reply": "2023-05-01T08:08:56.354956Z",
     "shell.execute_reply.started": "2023-05-01T08:08:56.310915Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.load('torch_checkpoints/name-generator-rnn.pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "755b71db-c234-4719-b43d-f0420fec9819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T08:09:00.131408Z",
     "iopub.status.busy": "2023-05-01T08:09:00.131408Z",
     "iopub.status.idle": "2023-05-01T08:09:00.291554Z",
     "shell.execute_reply": "2023-05-01T08:09:00.291554Z",
     "shell.execute_reply.started": "2023-05-01T08:09:00.131408Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chadal\n",
      "melan\n",
      "aniya\n",
      "hicer\n",
      "melmi\n",
      "ronsie\n",
      "arder\n",
      "kaymay\n",
      "camilae\n",
      "farlian\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "n_samples = 10\n",
    "temp = 0.7\n",
    "\n",
    "for i in range(n_samples):\n",
    "    x = torch.tensor(vocab(['<s>']), dtype=torch.long).to(dev)\n",
    "    x = x.unsqueeze(0)\n",
    "\n",
    "    while True:\n",
    "        logits = model(x)[:, -1, :]\n",
    "        probs = F.softmax(logits/temp, dim=1)\n",
    "        y = Categorical(probs).sample()\n",
    "        x = torch.cat((x, y.view(1, 1)), dim=1)\n",
    "        if y.item() == 1:\n",
    "            break\n",
    "\n",
    "    sample = ''.join(vocab.lookup_tokens(x.squeeze().tolist()))[3:-3]\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9655a9d-4aba-4024-a306-a9a0cf02a068",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "---\n",
    "\n",
    "1. http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "2. https://github.com/karpathy/makemore/\n",
    "\n",
    "3. https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:master-env-v1]",
   "language": "python",
   "name": "conda-env-master-env-v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
